{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, csv, re\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import random\n",
    "SEED = 448\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Lambda, Merge, Embedding\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, GRU, SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimensions 5328  rows: 37 cols= 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadBatch(year):\n",
    "    print 'loading data: ' + str(year)\n",
    "    with open('./data_batch/flood_label_' + str(year) + '.csv') as p:\n",
    "        s = p.read()\n",
    "    labels = s.split('\\n')[1:]\n",
    "    labels = labels[:-1]\n",
    "    labels = [float(x.split(',')[1]) for x in labels]\n",
    "    y_train = np.asarray(labels)\n",
    "    \n",
    "    files = os.listdir('./data_batch/')\n",
    "    # print files\n",
    "    pw = 8\n",
    "    t850 = 1\n",
    "    u300 = 2\n",
    "    u850 = 3\n",
    "    v300 = 4\n",
    "    v850 = 5\n",
    "    z300 = 6\n",
    "    z500 = 7\n",
    "    z1000 = 0\n",
    "\n",
    "    X = np.zeros((y_train.shape[0], 10, 9, 5328))\n",
    "\n",
    "    for f in files:\n",
    "        if f.split('_')[2][:-4] == str(year):\n",
    "            if f.split('_')[1] == 'z1000':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][z1000] = inputs[r+i]\n",
    "\n",
    "            if f.split('_')[1] == 't850':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][t850] = inputs[r+i]\n",
    "            if f.split('_')[1] == 'u300':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][u300] = inputs[r+i]\n",
    "            if f.split('_')[1] == 'u850':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][u850] = inputs[r+i]\n",
    "            if f.split('_')[1] == 'v300':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][v300] = inputs[r+i]\n",
    "            if f.split('_')[1] == 'v850':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][v850] = inputs[r+i]\n",
    "            if f.split('_')[1] == 'z300':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][z300] = inputs[r+i]\n",
    "            if f.split('_')[1] == 'z500':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][z500] = inputs[r+i]\n",
    "            if f.split('_')[1] == 'pw':\n",
    "                with open('./data_batch/' + f) as p:\n",
    "                    s = p.read()\n",
    "                    inputs = s.split('\\n')[1:]\n",
    "                    inputs = inputs[:-1]\n",
    "                    inputs = inputs[:y_train.shape[0]+9]\n",
    "                    inputs = [x.split(',')[4:] for x in inputs]\n",
    "                    inputs = np.asarray(inputs)\n",
    "#                     print inputs.shape\n",
    "                for r in range(y_train.shape[0]):\n",
    "                    for i in range(10):\n",
    "                        X[r][i][pw] = inputs[r+i]\n",
    "    X = X.reshape(y_train.shape[0], 10, 9, 37, 144)\n",
    "    return X, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: 1960\n",
      "loading data: 1959\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = loadBatch(1960)\n",
    "X_val, y_val = loadBatch(1959)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 10, 8, 37, 144)\n",
      "(352,)\n",
      "[ 0.444       0.          0.050952    0.27524     0.002381    0.          0.\n",
      "  0.00090909  0.          0.          0.0018182   0.0018182   0.015909\n",
      "  0.0013636   0.035       0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape\n",
    "print y_test.shape\n",
    "print y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========epoch 0===========\n",
      "loading data: 1948\n",
      "finish loading\n",
      "Train on 352 samples, validate on 351 samples\n",
      "Epoch 1/1\n",
      "352/352 [==============================] - 3s - loss: 0.0427 - acc: 0.4062 - val_loss: 0.0527 - val_acc: 0.2821\n",
      "loading data: 1949\n"
     ]
    }
   ],
   "source": [
    "epoch = 25\n",
    "nb_filter1 = 16\n",
    "nb_filter2 = 32\n",
    "hidden = 16\n",
    "min_loss = 1000000\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Convolution2D(nb_filter1, 5, 5, border_mode='valid', subsample=(1,3)), \n",
    "                               input_shape=(10, 9, 37, 144)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),border_mode='valid')))\n",
    "model.add(TimeDistributed(Convolution2D(nb_filter2, 3, 3, border_mode='valid', subsample=(2,3))))\n",
    "model.add(Activation('relu'))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),border_mode='valid')))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(SimpleRNN(output_dim=hidden))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(loss='mse',\n",
    "              optimizer=RMSprop(lr=0.0002, rho=0.9, epsilon=1e-08),\n",
    "              metrics=['accuracy'])\n",
    "for e in range(epoch):\n",
    "    print '===========' + 'epoch ' + str(e) + '==========='\n",
    "    for i in range(10):\n",
    "        X_train, y_train = loadBatch(1948+i)\n",
    "        print 'finish loading'\n",
    "        hist = model.fit(X_train,\n",
    "                  y_train,\n",
    "                  nb_epoch=1, \n",
    "                  validation_data = (X_val, y_val), \n",
    "                  shuffle=True)\n",
    "        cur_loss = hist.history['val_loss'][0]\n",
    "        if cur_loss < min_loss:\n",
    "            min_loss = cur_loss\n",
    "            model.save('model/cnn_lstm.h5')\n",
    "            \n",
    "model = load_model('model/cnn_lstm.h5')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 1s     \n",
      "[0.036504719787361944, 0.36079545454545453]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/cnn_lstm.h5')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print score\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation split in each batch [0.036504719787361944, 0.36079545454545453]\n",
    "LSTM fix validation set 1959 [0.031095882793041794, 0.36079545454545453]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "timedistributed_26 (TimeDistribut(None, 10, 32, 33, 47)7232        timedistributed_input_9[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 10, 32, 33, 47)0           timedistributed_26[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_27 (TimeDistribut(None, 10, 32, 16, 23)0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_28 (TimeDistribut(None, 10, 16, 14, 7) 4624        timedistributed_27[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 10, 16, 14, 7) 0           timedistributed_28[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_29 (TimeDistribut(None, 10, 16, 7, 3)  0           activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_30 (TimeDistribut(None, 10, 336)       0           timedistributed_29[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 32)            35424       timedistributed_30[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 32)            0           gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 32)            0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 32)            1056        activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 32)            0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 32)            0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 32)            1056        dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 32)            0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 32)            0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             33          dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 1)             0           dense_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 49425\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
